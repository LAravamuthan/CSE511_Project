
%-------------------------------LATEX SYNTAX----------------------------------
%
%	enter:				\\, \linebreak, \newline
%	new page: 			\newpage
%	tab:				\tab
%	new section:		\section{name} text
%	new paragraph		\subsection{name} text	(subsub...section{name} for more layers)
%	refer:				\nameref{label name}	(place "\label{name}" at the position you want to refer to)
%	%, &, $, etc:		\%, \&, \$, etc		(these are latex operators, add a "\" to type it as text)
%	add comment:		\commred{text}, \commblue{text}, \commpurp{text}, \commgreen{text}
%	bullet points:		\begin{itemize} \item{text} ... \item{text} \end{itemize}
%	clean code:			\cleancode{text}
%	idem without indent:\cleanstyle{text}
%	bold, italic, under:\textbf{text}, textit{text}, \underline{text}
%	table:				\begin{tabular}{c c c} text \end{tabular}	('&' for tab, '\\' for new line)
%
%	use Google for the rest
%
%------------------------------------------------------------------------------

\documentclass[a4paper]{article}

\usepackage[utf8x]{inputenc}
\usepackage[british,UKenglish]{babel}
\usepackage{amsmath}
%\usepackage{titlesec}
\usepackage{color}
\usepackage{graphicx}
\usepackage{fancyref}
\usepackage{hyperref}
\usepackage{float}
\usepackage{scrextend}
\usepackage{setspace}
\usepackage{xargs}
\usepackage{multicol}
\usepackage{nameref}
\usepackage[pdftex,dvipsnames]{xcolor}
\usepackage{sectsty}

\graphicspath{ {images/} }
\newcommand\tab[1][1cm]{\hspace*{#1}}
\hypersetup{colorlinks=true, linkcolor=black}
\interfootnotelinepenalty=10000
%\titleformat*{\subsubsection}{\large\bfseries}
\subsubsectionfont{\large}
\subsectionfont{\Large}
\sectionfont{\LARGE}
\definecolor{cleanOrange}{HTML}{D14D00}
\definecolor{cleanYellow}{HTML}{FFFF99}
\definecolor{cleanBlue}{HTML}{3d0099}
%\newcommand{\cleancode}[1]{\begin{addmargin}[3em]{3em}\fcolorbox{cleanOrange}{cleanYellow}{\texttt{\textcolor{cleanOrange}{#1}}}\end{addmargin}}
\newcommand{\cleancode}[1]{\begin{addmargin}[3em]{3em}\texttt{\textcolor{cleanOrange}{#1}}\end{addmargin}}
\newcommand{\cleanstyle}[1]{\text{\textcolor{cleanOrange}{\texttt{#1}}}}


\usepackage[colorinlistoftodos,prependcaption,textsize=footnotesize]{todonotes}
\newcommandx{\commred}[2][1=]{\textcolor{Red}
{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}}
\newcommandx{\commblue}[2][1=]{\textcolor{Blue}
{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}}
\newcommandx{\commgreen}[2][1=]{\textcolor{OliveGreen}{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}}
\newcommandx{\commpurp}[2][1=]{\textcolor{Plum}{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}}


%-----------------------------------------BEGIN DOC----------------------------------------

\begin{document}

\title{
{\Huge CSE 511: Group 18{\large\linebreak\\} System Documentation{\large\linebreak\\}}
}
\author{
Aravamuthan Lakshminarayanan\\
1215338579\\\\
Muffakham Ali Farhan Mohammed\\
1211111111\\\\
Rahul Manghnani\\
1217633183\\\\
Shahabudeen Sajith\\
1216259811\\\\
Vivek Tiwary\\
1217045934\\\\
Sudarsan Balaji Manikandan\\
1211111111\\\\
}
\date{1 December 2019}
\maketitle
\newpage


\tableofcontents\label{c}
\newpage

\section{Tasks} \label{Tasks}
	\subsection{Phase 1} \label{Phase 1}
    The tasks for Phase 1 involved writing user-defined functions in SparkSQL and using them to perform spatial queries.\\

    The \textbf{functions} to be implemented are as follows:

    \subsubsection{\cleanstyle{ST\_Contains(queryRectangle, pointString)}}
    \cleancode{
    ST\_Contains(queryRectangle: String, pointString: String): Boolean
    }

    Parse the \cleanstyle{pointString} and \cleanstyle{queryRectangle} and check whether the \cleanstyle{queryRectangle} fully contains the point.

    \subsubsection{\cleanstyle{ST\_Within(pointString1, pointString2, distance)}}
    Parse the \cleanstyle{pointString1} and \cleanstyle{pointString2} and check the two points are within the given (Euclidean) \cleanstyle{distance}.\\

    The \textbf{spatial queries} to be performed are as follows:

    \subsubsection{\cleanstyle{Range}}
    Given a query rectangle \cleanstyle{R} and a set of points \cleanstyle{P}, find all the points within \cleanstyle{R}.

    \subsubsection{\cleanstyle{Range Join}}
    Given a set of Rectangles \cleanstyle{R} and a set of Points \cleanstyle{S}, find all \cleanstyle{(Point, Rectangle)} pairs such that the point is within the rectangle.

    \subsubsection{\cleanstyle{Distance}}
    Given a point location \cleanstyle{P} and distance \cleanstyle{D}, find all points that lie within a distance \cleanstyle{D} from \cleanstyle{P}.

    \subsubsection{\cleanstyle{Distance Join}}
    Given a set of Points \cleanstyle{S1} and a set of Points \cleanstyle{S2} and a distance \cleanstyle{D}, find all \cleanstyle{(s1, s2)} pairs such that \cleanstyle{s1} is within a distance \cleanstyle{D} from \cleanstyle{s2}.

    \subsection{Phase 2} \label{Phase 1}%----------
    The tasks for Phase 2 involved performing spatial hot spot analysis.\\

    \subsubsection{Hot zone analysis}
    The hotness of a rectangle is defined as the count of the number of points located inside it. Given a rectangle and points dataset, the task is to calculate the hotness of all the rectangles.

    \subsubsection{Hot cell analysis}
    This task was to apply spatial statistics to spatio-temporal big data in order to identify statistically significant spatial hot spots. Concretely, compute a list of the fifty most significant hot spot cells in time and space as identified using the Getis-Ord $G_i^*$ statistic
    \begin{equation}
        G_i^*
        =
        \frac
        {
        \sum_{j=1}^{n}
        w_{i,j} x_j
        -
        \bar{X}
        \sum_{j=1}^{n}
        w_{i,j}
        }
        {
        S
        \sqrt
        {
        \frac
        {
        [
        n
        \sum_{j=1}^{n}
        w_{i,j}^2
        -
        (
        \sum_{j=1}^{n}
        w_{i,j}
        )^2
        ]
        }
        {
        n - 1
        }
        }
        }
    \end{equation}

    where $x_j$ is the attribute value for cell $j$ , $w_{i,j}$ is the spatial weight between cell $i$ and  $j$, $n$ is equal to the total number of cells, and:

    \begin{equation}
        \bar{X}
        =
        \frac
        {
        \sum_{j=1}^{n}
        x_j
        }
        {
        n
        }
    \end{equation}

    \begin{equation}
        S
        =
        \sqrt
        {
        \frac
        {
        \sum_{j=1}^{n}
        x_j^2
        }
        {
        n
        }
        -
        (
        \bar{X}
        )^2
        }
    \end{equation}

    The $G_i^*$ statistic is a z-score. The neighborhood for each cell in the space-time cube is established by the neighbors in a grid based on subdividing latitude and longitude uniformly. This spatial neighborhood is created for the preceding, current, and following time periods (i.e., each cell has 26 neighbors). For simplicity of computation, the weight of each neighbor cell is presumed to be equal.

\newpage

\section{Environment} \label{Environment}
The code is written in Scala to run against Apache Spark. IntelliJ is the IDE of choice. A system with at least 8 GB of RAM and 128 GB of Storage is recommended for locally running the Spark application.

\subsection{Requirements}
\begin{enumerate}
    \item JDK 1.8.0
    \item Python 3.6
    \item Scala 2.11.12
    \item Spark 2.4.4
    \item sbt 0.13.17
\end{enumerate}

\subsection{Path}
\cleancode{
export JAVA\_HOME=$\sim$/jdk1.8.0\_162.jdk/Contents/Home \\
export SPARK\_HOME=$\sim$/spark-2.4.4-bin-hadoop2.7 \\
export SBT\_HOME=$\sim$/sbt \\
export SCALA\_HOME=$\sim$/scala-2.11.12 \\
export PYSPARK\_PYTHON=python3 \\
export PATH="$\sim$/Python.framework/Versions/3.6/bin":\$PATH \\
export PATH=\$JAVA\_HOME/bin:\$PATH \\
export PATH=\$SBT\_HOME/bin:\$PATH \\
export PATH=\$SBT\_HOME/lib:\$PATH \\
export PATH=\$SCALA\_HOME/bin:\$PATH \\
export PATH=\$SCALA\_HOME/lib:\$PATH \\
export PATH=\$SPARK\_HOME/bin:\$PATH \\
export PATH=\$SPARK\_HOME/lib:\$PATH
}

\subsection{Source Code}
The source code for the entire project is hosted as a private repository over Github. \href{https://github.com/hexhog/CSE511_Project}{https://github.com/hexhog/CSE511\_Project}


\subsection{IntelliJ Setup}
\begin{enumerate}
\item Import the project into the IDE.
\item Select the JDK and Scala version when prompted.
\item Once the project is up and the dependencies have been installed, right click on the main class and select run. The main class for Phase 1 is \cleanstyle{SparkSqlExample.scala} and the main class for Phase 2 is \cleanstyle{Entrance.scala}
\item Append \cleanstyle{.master("local[\*]")} after  \cleanstyle{.config("spark.some.config.option", "some-value")} to tell IDE the master IP is localhost.
\end{enumerate}

\subsection{Submitting the code to Spark}
\begin{enumerate}
    \item Go to project root folder.
    \item Run \cleanstyle{sbt clean assembly}
    \item Find the packaged jar in \cleanstyle{target/scala-2.11/}
    \item Submit the jar to Spark using Spark command \cleanstyle{spark-submit target/scala-2.11/\_.jar}.
\end{enumerate}

\subsection{Testing on a cluster locally}
\begin{enumerate}
    \item Start the master \cleanstyle{spark-2.4.4-bin-hadoop2.7/sbin/start-master.sh}
    \item Spawn workers in separate shells \cleanstyle{spark-2.4.4-bin-hadoop2.7/bin/spark-class }\\ \cleanstyle{org.apache.spark.deploy.worker.Worker  spark://localhost:7077 -c 1 -m 1024M}
    \item Submit the jar to the master using \\ \cleanstyle{spark-submit --master spark://localhost:7077 target/scala-2.11/\_.jar}.
\end{enumerate}

\newpage

\section{Phase 1} \label{Phase 1}

\subsection{Implementation}

\subsubsection{\cleanstyle{ST\_Contains(queryRectangle, pointString)}}
\cleanstyle{ST\_Contains} first computes the four corner points, each as a pair of coordinates, for the given \cleanstyle{queryRectangle}. The function then checks if the coordnate pair given by \cleanstyle{pointString} lies in between these coordinates.

\subsubsection{\cleanstyle{ST\_Within(pointString1, pointString2, distance)}}
\cleanstyle{ST\_Contains} computes the Euclidean distance between the two coordinates given by \cleanstyle{pointString1} and \cleanstyle{pointString2}. This distance is then compared with \cleanstyle{distance}.

\subsubsection{\cleanstyle{Range}}
\cleanstyle{Range} calls \cleanstyle{ST\_Contains} on the given set of points and rectangle.

\subsubsection{\cleanstyle{Range Join}}
\cleanstyle{Range Join} calls \cleanstyle{ST\_Contains} on the given set of points and the set of rectangles.

\subsubsection{\cleanstyle{Distance}}
\cleanstyle{Distance} calls \cleanstyle{ST\_Within} on the source point and the given set of points.

\subsubsection{\cleanstyle{Distance Join}}
\cleanstyle{Distance Join} calls \cleanstyle{ST\_Within} between the two sets of points.

\subsection{Testing}
The code was tested against the given sample example input.

\cleancode{
spark-submit target/scala-2.11/Phase1.jar result/output  \\
rangequery  src/resources/arealm10000.csv  \\
-93.63173,33.0183,-93.359203,33.219456  \\
rangejoinquery  src/resources/arealm10000.csv  \\
src/resources/zcta10000.csv  \\
distancequery  src/resources/arealm10000.csv  \\
-88.331492,32.324142  1 \\
distancejoinquery  \\
src/resources/arealm10000.csv  src/resources/arealm10000.csv  0. \\
}

The output matched the given sample output.

\cleancode{4 7612 302 123362}

\newpage

\section{Phase 2} \label{Phase 2}

\subsection{Implementation}

\subsubsection{Hot zone}

The hot zone analysis takes two CSV files as input. Picup points are extracted from the first file. The rectangle boundaries are extracted from the second file. These recatangles are the zones on which the hot zone analysis has to be performed. The basic workflow for hot zone analysis is as follows
\begin{enumerate}
    \item Parse the input CSV files to load point data.
    \item Parse the input CSV files to load rectangle data.
    \item  Join the point data and rectangle data using \cleanstyle{ST\_Contains} (from Phase 1) to get all points which lie within the extracted rectangles. 
    \item Run a count aggregate function on the join result to count the number of points found within each rectangle. We have grouped by the rectangle column since the join result will have multiple point entries for the same rectangle data and we need to count these repeating rectangles.
    \item Order the result by the rectangle column to follow the ordering expected in the problem statement.
\end{enumerate}

\subsubsection{Hot cell}

\begin{enumerate}
    \item \textbf{Getting pairs(cells) in range :} To obtain pairs of x, y and z values in which x and y are coordinates and z is the day of the month, we did a select query from all data set and stored the results as a view (CELLSOFINTEREST) to be used later  with predicate being the fact that x, y and z each should be in range of min and max values of x, y and z provided.
    \item \textbf{Getting counts of unique pairs :} To obtain unique pairs of x, y and z from the previously created view(CELLSOFINTEREST), we do another select query with grouping on x,y and z and also making a column of individual cell combination frequencies(this column is to be used later for further calculation) and store as a view(CELLFREQUENCYVIEW).
    \item \textbf{Finding the mean :} For obtaining mean we make use of the previously created view(CELLFREQUENCYVIEW), to get the total sum of all frequencies, then dividing it by the total number of cells gives us the mean of all frequency values.
    \item \textbf{Finding the standard deviation :} We know that variance is  Var(X) = E(X2) - E(X)2 and standard deviation (σ) is the square root of variance. We already have the first moment that is E(X) (mean) and we need to find the second moment E(X2). To get the same we first get the squared values each from previously created view using a User Defined Function (SQUARED) and then getting the sum total of squared frequencies, dividing this value with total number of cells in consideration gives us the second moment. With E(X2) and E(X), we obtain the standard deviation.
    \item \textbf{Finding the neighbouring cells and their contribution :} Surrounding Cells are found by running an inner join on the cells frequency table (CELLFREQUENCYVIEW), the inner join has to be done such that it considers only adjacents cells, for 3 dimensional(x, y and z) data each cell has (3 * 3 * 3 - 1) neighbour(s) (-1 here is to remove itself)  likewise if the cell is at the corners then the degree of freedom of that dimension decreases, hence a cell at x corner has (2 * 3 * 3 - 1) neighbour(s) or cells at x, y and z corners have (2 * 2 * 2 - 1) corners. To handle all these test cases in finding the neighbours we have used a user-defined function SurroundingCells. To find the contributions of the neighbour for each x,y,z we use sum aggregate function on neighbouring frequencies. Using these data we create a view which will have five columns -  no. of surrounding cells, X, Y and Z of the cell in question and sums of frequency contribution.
    \item \textbf{Finding the Zscore :} We use a user-defined function ZScore to calculate the Zscore for an individual cell, using the number of neighbouring cells and their contributions for each cell. We also use the fact that the weight of the individual cell is homogeneous and equal to 1. Hence we use the formula previously discussed and get the Zscore for individual cell and store the cells in descending order of Z-scores (in view finalResultsView) and return the corresponding results.
\end{enumerate}

\subsection{Testing}
The code was tested against the given sample example input.

\cleancode{
spark-submit target/scala-2.11/Phase2.jar result/output \\
hotzoneanalysis src/resources/point-hotzone.csv \\ src/resources/zone-hotzone.csv \\
hotcellanalysis src/resources/yellow\_tripdata\_2009-01\_point.csv \\
}

The output matched the given sample output.

\newpage

\section{Process}

\subsection{Team collaboration strategy}
\begin{enumerate}
    \item Meeting in the library with all teammates to discuss about the approaches for the problem at hand.
    \item Distribute the tasks among teammates during meet up. 
    \item If tasks were too big/complicated for a single person, two people were paired to finish the task.
    \item Discuss any issues being faced by any teammate and provide support accordingly in getting the issue resolved.
\end{enumerate}

\subsection{Code merging strategy}
\begin{enumerate}
    \item Code source was hosted on a private GitHub repository accessible only to team-members.
    \item The master branch is the base branch.
    \item Each new task required creating a feature branch from master and pushing the changes to feature branch.
    \item Once the code was tested successfully on feature branch, a pull request (PR) to merge the changes to master was created and pushed to master. This ensured a stable code is pushed and does not break the current code.
\end{enumerate}

\newpage

\section{Task Distribution}

\subsection{Aravamuthan Lakshminarayanan}
\begin{enumerate}
    \item Implemented Hot cell analysis of Phase 2
    \item Tested and verified overall Phase 2 in local spark cluster 
    \item Tested and verified Phase 1 local spark cluster
    \item Contributed to System Documentation report.
    \item Distributed Task for phase 2.
\end{enumerate}

\subsection{Muffakham Ali Farhan Mohammed}
\begin{enumerate}
    \item
\end{enumerate}

\subsection{Rahul Manghnani}
\begin{enumerate}
    \item Implemented Hot Zone Analysis of Phase 2.
		\item Tested and verified Hot Zone Analysis on local Spark server with all datasets.
		\item Contributed to System Documentation report.
\end{enumerate}

\subsection{Shahabudeen Sajith}
\begin{enumerate}
    \item Shared documentation to setup the environment.
    \item Implemented Phase 1 of the project.
    \item Tested Phase 2 of the project on local cluster setup.
    \item Contributed to System Documentation report.
\end{enumerate}

\subsection{Vivek Tiwary}
\begin{enumerate}
    \item Implemented Hot cell analysis of Phase 2
    \item Tested and verified overall Phase 2 in local spark cluster
    \item Tested and verified Phase 1 local spark cluster
    \item Contributed to System Documentation report.
    \item Took care of SBT ASSEMBLY for both phases.
\end{enumerate}

\subsection{Sudarsan Balaji Manikandan}
\begin{enumerate}
    \item 
\end{enumerate}



\newpage


\end{document}
